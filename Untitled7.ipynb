{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPbvV2iD3MNL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " 1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x\n",
        " -  TensorFlow 2.0 is a popular open-source machine learning framework developed by Google. The primary difference between TensorFlow 2.0 and TensorFlow 1.x lies in their approach to building and executing computational graphs. TensorFlow 2.0 introduces eager execution, which allows for more intuitive and flexible model development.\n",
        "\n"
      ],
      "metadata": {
        "id": "_RyexkCw3PKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How do you install TensorFlow 2.0\n",
        "-  using\n",
        "            pip install tensorflow==2.0.0\n",
        "            pip install tensorflow-gpu==2.0.0\n",
        "- for verifying\n",
        "            import tensorflow as tf\n",
        "            print(tf.__version__)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ydpbCUq-3lAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  What is the primary function of the tf.function in TensorFlow 2.0\n",
        "-   The primary function of tf.function is to convert a Python function into a TensorFlow graph for optimized execution.\n",
        "\n"
      ],
      "metadata": {
        "id": "j3yH1G5F4foj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the purpose of the Model class in TensorFlow 2.0\n",
        "-   In TensorFlow 2.0, the Model class (from tf.keras.Model) is the core building block for creating and managing machine learning models."
      ],
      "metadata": {
        "id": "btaKJBuf4ywU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do you create a neural network using TensorFlow 2.0\n",
        "-   There are three common ways to build a neural network in TensorFlow 2.0 using the tf.keras API:\n",
        "       1. using sequential API\n",
        "       2. using the functional API\n",
        "       3. using subclassing(tf.keras.model)"
      ],
      "metadata": {
        "id": "qf66GQ2a5NGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  What is the importance of Tensor Space in TensorFlow\n",
        "-  Tensors are the fundamental data structure in TensorFlow, representing multi-dimensional arrays. Understanding tensor operations is crucial for building and manipulating computational graphs.\n",
        "\n"
      ],
      "metadata": {
        "id": "kG7mSl2U6MJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How can TensorBoard be integrated with TensorFlow 2.0\n",
        "-  TensorBoard is a visualization tool that can be integrated with TensorFlow 2.0 to monitor training metrics, visualize model graphs, and more. we can use the tf.keras.callbacks.TensorBoard callback to log data to TensorBoard."
      ],
      "metadata": {
        "id": "W0oJeurI-ltB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the purpose of TensorFlow Playground\n",
        "-   TensorFlow Playground is an interactive visualization tool for exploring neural networks. It allows users to experiment with different network architectures and hyperparameters.\n"
      ],
      "metadata": {
        "id": "Cp9xjNlG-3DO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  What is Netron, and how is it useful for deep learning models\n",
        "-    Netron is a viewer for neural network models. It supports various formats, including TensorFlow and Keras models. Netron is useful for visualizing and understanding the architecture of deep learning models."
      ],
      "metadata": {
        "id": "amds-7PM_BNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.  What is the difference between TensorFlow and PyTorch\n",
        "-   Both TensorFlow and PyTorch are popular deep learning frameworks. While TensorFlow is known for its production-ready features and support for distributed training, PyTorch is renowned for its ease of use and rapid prototyping capabilities. The choice between the two ultimately depends on our specific needs and preferences."
      ],
      "metadata": {
        "id": "QU-JYrr8_NuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.  How do you install PyTorch\n",
        "-  using pip\n",
        "            pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "eptE_lb-_-6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the basic structure of a PyTorch neural network\n",
        "-   A PyTorch neural network typically consists of the following components:\n",
        "- Neural Network Class: Define a class that inherits from torch.nn.Module.\n",
        "- Layers: Define layers in the __init__ method using torch.nn modules.\n",
        "- Forward Method: Define the forward pass through the network in the forward method.\n",
        "\n"
      ],
      "metadata": {
        "id": "4uxK65L2ASPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.  What is the significance of tensors in PyTorch\n",
        "-   Tensors are multi-dimensional arrays that serve as the fundamental data structure in PyTorch. They are used to represent inputs, outputs, and intermediate results in neural networks.\n",
        "\n"
      ],
      "metadata": {
        "id": "sqD0RFTDAnLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.  What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch\n",
        "- torch.Tensor: Represents a tensor on the CPU.\n",
        "- torch.cuda.Tensor: Represents a tensor on the GPU, allowing for accelerated computations.\n"
      ],
      "metadata": {
        "id": "CXsxZO2oBSup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  What is the purpose of the torch.optim module in PyTorch\n",
        "-  The torch.optim module provides various optimization algorithms for training neural networks, such as stochastic gradient descent (SGD) and Adam.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bGI7t2P7B9Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.  What are some common activation functions used in neural networks.\n",
        "-\n",
        "Some common activation functions used in neural networks include:\n",
        "- ReLU (Rectified Linear Unit): torch.nn.ReLU()\n",
        "- Sigmoid: torch.nn.Sigmoid()\n",
        "- Tanh: torch.nn.Tanh()\n"
      ],
      "metadata": {
        "id": "wxhbIjDFCLGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.  What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch\n",
        "-    torch.nn.Module: A base class for neural network modules, allowing for flexible and complex model definitions.\n",
        "- torch.nn.Sequential: A container for a sequence of modules, providing a simpler way to define linear neural network architectures.\n"
      ],
      "metadata": {
        "id": "A7b2TxOWCqXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. How can you monitor training progress in TensorFlow 2.0\n",
        "-  we can monitor training progress in TensorFlow 2.0 using:\n",
        "- TensorBoard: A visualization tool that provides insights into training metrics and model performance.\n"
      ],
      "metadata": {
        "id": "ge3bgfGkC4Du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.  How does the Keras API fit into TensorFlow 2.0\n",
        "-  The Keras API is a high-level interface for building and training deep learning models. It's now the default high-level API in TensorFlow 2.0, providing an easy-to-use interface for rapid prototyping and experimentation.Â²\n"
      ],
      "metadata": {
        "id": "TMk1B3hFDHFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0\n",
        "  -  some examples of deep learning projects that can be implemented using TensorFlow 2.0 :\n",
        "  - Image Classification: Build a convolutional neural network (CNN) to classify images into different categories. TensorFlow 2.0 provides tools like Keras API and tf.data to make it easier to work with image data.\n",
        "  - Natural Language Processing (NLP): Implement NLP tasks like text classification, sentiment analysis, and language modeling using recurrent neural networks (RNNs) or transformers.\n",
        "  - Time Series Forecasting: Use TensorFlow 2.0 to predict future values in a time series dataset, such as stock prices or weather forecasts.\n",
        "  - Generative Adversarial Networks (GANs): Create GANs to generate new images or data that resemble existing data.\n",
        "  - Object Localization: Implement object detection and localization using TensorFlow 2.0 and CNNs.\n",
        "  - DeepDream: Use TensorFlow 2.0 to generate artistic images using the DeepDream algorithm.\n",
        "  - Deploying Models: Learn how to deploy trained models using TensorFlow Serving, TensorFlow Lite, and other tools.\n",
        "  - Distributed Training: Use TensorFlow's distribution strategies to parallelize training and speed up model development.\n",
        "\n"
      ],
      "metadata": {
        "id": "CMN-e6ckDUvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.  What is the main advantage of using pre-trained models in TensorFlow and PyTorch?.\n",
        "-  Using pre-trained models in TensorFlow and PyTorch offers several advantages, including:\n",
        "  - Transfer Learning: Leverage knowledge learned from large datasets to improve performance on smaller datasets.\n",
        "  - Faster Development: Reduce training time and computational resources by building upon existing models.\n",
        "  - Improved Performance: Achieve better results by fine-tuning pre-trained models on specific tasks."
      ],
      "metadata": {
        "id": "ccorTY7nElhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---   PRACTICAL QUESTION -----**"
      ],
      "metadata": {
        "id": "LzFEPauHFCUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQp4OC3cFKAM",
        "outputId": "1ced547e-5b71-420b-dc22-206de6d7995c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "print(add(tf.constant(3), tf.constant(5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um49LUXlJFuh",
        "outputId": "29fe56e6-1260-483f-87f6-63a4b9125248"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(10,)),\n",
        "    Dense(1)\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGz9epMbJQjW",
        "outputId": "5f117edb-acc9-4f87-fb3b-e033fcf6faec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model and store the training history\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rJf9vf7kJjeb",
        "outputId": "84705dea-eda7-4764-b52a-ed45f3ede46a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20-275945688.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model and store the training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Plot training and validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "import torch\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw4fpINTQpkB",
        "outputId": "bf2c85d8-3bc0-44c7-9e6a-382de4574a10"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: False\n",
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "KhW6cpZQQpnC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 10)\n",
        "        self.fc2 = nn.Linear(10, 1)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "VDlFAdVMSqHW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN()\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKDAl0O4S0Jp",
        "outputId": "65ade2a4-4a3d-491c-dcfb-550f7393aa8a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_input = torch.randn(5, 4)\n",
        "output = model(sample_input)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsEgupWZS-xw",
        "outputId": "f11e3e4b-93e4-4e41-958e-75b8414587a0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0447],\n",
            "        [-0.5824],\n",
            "        [-0.1223],\n",
            "        [ 0.1150],\n",
            "        [ 0.2163]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 10)\n",
        "        self.fc2 = nn.Linear(10, 1)\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = SimpleNN()\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "x_train = torch.randn(100, 4)\n",
        "y_train = torch.randn(100, 1)\n",
        "for epoch in range(5):\n",
        "    outputs = model(x_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz5WxklwRRhW",
        "outputId": "f0028094-1d49-43eb-e26b-b0ccbd1a4a75"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.1882\n",
            "Epoch 2, Loss: 1.1740\n",
            "Epoch 3, Loss: 1.1638\n",
            "Epoch 4, Loss: 1.1570\n",
            "Epoch 5, Loss: 1.1514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 10)\n",
        "        self.fc2 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        mse = torch.mean((output - target) ** 2)\n",
        "        l1 = torch.mean(torch.abs(output - target))\n",
        "        return mse + 0.1 * l1\n",
        "\n",
        "\n",
        "model = SimpleNN()\n",
        "criterion = CustomLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Dummy data\n",
        "x_train = torch.randn(100, 4)\n",
        "y_train = torch.randn(100, 1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "    outputs = model(x_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBXBJlQKTyw_",
        "outputId": "b8676418-446b-4212-b74a-c044f0881016"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5175\n",
            "Epoch 2, Loss: 1.4704\n",
            "Epoch 3, Loss: 1.4323\n",
            "Epoch 4, Loss: 1.4022\n",
            "Epoch 5, Loss: 1.3790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(4,)),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.save('model.h5')\n",
        "model = tf.keras.models.load_model('model.h5')\n",
        "\n",
        "sample_input = np.random.rand(1, 4).astype(np.float32)\n",
        "print(\"Prediction:\", model.predict(sample_input, verbose=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "uIVPNXmmVw-D",
        "outputId": "d3097435-0ef0-4be3-af04-63a28984d715"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-43-4279978672.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 3. Load from .h5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 4. Test prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# Compile model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             model.compile(\n\u001b[0;32m--> 155\u001b[0;31m                 **saving_utils.compile_args_from_training_config(\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0mtraining_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mcompile_args_from_training_config\u001b[0;34m(training_config, custom_objects)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mloss_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_nested_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Ensure backwards compatibility for losses in legacy H5 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resolve_compile_arguments_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36m_deserialize_nested_config\u001b[0;34m(deserialize_fn, config)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_single_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         return {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/losses/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mKeras\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m     return serialization_lib.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mALL_OBJECTS_DICT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 return deserialize_keras_object(\n\u001b[0m\u001b[1;32m    576\u001b[0m                     serialize_with_public_fn(\n\u001b[1;32m    577\u001b[0m                         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_module_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"function\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mfn_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         return _retrieve_class_or_fn(\n\u001b[0m\u001b[1;32m    679\u001b[0m             \u001b[0mfn_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mregistered_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36m_retrieve_class_or_fn\u001b[0;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;34mf\"Could not locate {obj_type} '{name}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;34m\"Make sure custom classes are decorated with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
          ]
        }
      ]
    }
  ]
}